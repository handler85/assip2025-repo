{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0daffd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "from botocore.client import Config\n",
    "\n",
    "# --- IMPORTANT: Set your DigitalOcean credentials and Space information ---\n",
    "os.environ['SPACES_ACCESS_KEY'] = 'DO801NGY2P92FAUZUQJH'\n",
    "os.environ['SPACES_SECRET_KEY'] = 'H0uQz+d/Vjbek70S9YcT84iq9sMEnGaHPEI5H3ydv58'\n",
    "\n",
    "# The endpoint URL for your Space (e.g., nyc3.digitaloceanspaces.com)\n",
    "# You can find this in your Space's settings.\n",
    "SPACES_ENDPOINT_URL = 'https://assip2025storage.nyc3.digitaloceanspaces.com' # Change to your region\n",
    "SPACES_BUCKET_NAME = 'assip2025storage' # Change to your Space's name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eac81b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d270e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "\n",
    "# --- Configuration (from Step 2) ---\n",
    "# Ensure your credentials are set as environment variables for security\n",
    "SPACES_ACCESS_KEY = os.getenv('SPACES_ACCESS_KEY')\n",
    "SPACES_SECRET_KEY = os.getenv('SPACES_SECRET_KEY')\n",
    "\n",
    "# --- Function to Upload a Directory ---\n",
    "def upload_directory_to_space(local_directory, bucket_name, spaces_endpoint_url, access_key, secret_key):\n",
    "    \"\"\"\n",
    "    Uploads the contents of a directory to a DigitalOcean Space.\n",
    "\n",
    "    :param local_directory: Path to the local directory.\n",
    "    :param bucket_name: Name of the DigitalOcean Space (bucket).\n",
    "    \"\"\"\n",
    "    print(f\"Connecting to DigitalOcean Space: {bucket_name}\")\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client('s3',\n",
    "                            region_name=spaces_endpoint_url.split('.')[1], # e.g., 'ams3'\n",
    "                            endpoint_url=spaces_endpoint_url,\n",
    "                            aws_access_key_id=access_key,\n",
    "                            aws_secret_access_key=secret_key)\n",
    "    \n",
    "    print(f\"Starting upload from '{local_directory}'...\")\n",
    "    for root, dirs, files in os.walk(local_directory):\n",
    "        for filename in files:\n",
    "            local_path = os.path.join(root, filename)\n",
    "            # Create a relative path for the object in the Space\n",
    "            relative_path = os.path.relpath(local_path, local_directory)\n",
    "            # On Windows, path separators are '\\', S3 uses '/'.\n",
    "            s3_path = relative_path.replace(\"\\\\\", \"/\")\n",
    "\n",
    "            print(f\"Uploading {local_path} to s3://{bucket_name}/{s3_path}\")\n",
    "            try:\n",
    "                client.upload_file(local_path, bucket_name, s3_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error uploading {local_path}: {e}\")\n",
    "                return False\n",
    "    print(\"Upload complete.\")\n",
    "    return True\n",
    "\n",
    "# --- Main Script ---\n",
    "\n",
    "# 1. Define the model and a temporary local cache directory\n",
    "model_name = \"EleutherAI/pythia-1.4b-deduped\" # Example model\n",
    "local_temp_cache = Path(\"./temp_model_cache\")\n",
    "local_temp_cache.mkdir(exist_ok=True) # Create the directory if it doesn't exist\n",
    "\n",
    "print(f\"Downloading model '{model_name}' to temporary local cache: {local_temp_cache}\")\n",
    "\n",
    "# 2. Download the model using the transformers library\n",
    "# The `cache_dir` argument tells Hugging Face where to save the files.\n",
    "try:\n",
    "    pipeline = transformers.pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model_name,\n",
    "        cache_dir=str(local_temp_cache)\n",
    "    )\n",
    "    print(\"Model download complete.\")\n",
    "\n",
    "    # 3. Upload the entire cache directory to DigitalOcean Spaces\n",
    "    if upload_directory_to_space(str(local_temp_cache), SPACES_BUCKET_NAME, SPACES_ENDPOINT_URL, SPACES_ACCESS_KEY, SPACES_SECRET_KEY):\n",
    "        # 4. Clean up the local directory to free space\n",
    "        print(f\"Successfully uploaded to Spaces. Deleting local directory: {local_temp_cache}\")\n",
    "        shutil.rmtree(local_temp_cache)\n",
    "        print(\"Local cache deleted.\")\n",
    "    else:\n",
    "        print(\"Upload failed. Local files have not been deleted.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during download: {e}\")\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5988dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f22962e1e82b41fdbc3a5cd6aca199f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d46ce9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import json\n",
    "from transformers import TextStreamer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ba975c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5d49aa0b6874c9cbab0ee883207dc68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/212 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mlevi\\miniconda3\\envs\\assip2025\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\mlevi\\.cache\\huggingface\\hub\\datasets--cat-searcher--minif2f-lean4. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be0916ce5d9f45279fdab19d54ef0cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "valid.jsonl: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e73b25bc4aa4f61aaf467123a006c09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test.jsonl: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de34e8cc0cee420aa0c5b329fb51a206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/244 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c03b96e4cad5457d817b5283d37ea027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/244 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = load_dataset(\"cat-searcher/minif2f-lean4\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ef5c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "model_id = \"RickyDeSkywalker/TheoremLlama\"\n",
    "tok  = AutoTokenizer.from_pretrained(model_id, cache_dir=CACHE_DIR)\n",
    "bnb_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_compute_dtype=torch.float16)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "            MODEL_ID,\n",
    "            quantization_config=bnb_config,\n",
    "            device_map=\"auto\",            # Colab T4 / A10 will work\n",
    "            cache_dir=CACHE_DIR\n",
    "        )\n",
    "streamer = TextStreamer(tok)             # prints streaming tokens for visibility\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assip2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
